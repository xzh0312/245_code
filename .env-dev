# this variable is for test purpose
ENV_NAME="dev"

# network proxy
# NETWORK_PROXY="http://192.168.2.1:1081"

# call interval
# LLM_API_CALL_INTERVAL=3

# # groq llama  30rpm, 1000rpd
# LLM_BASE_URL=""
# LLM_API_KEY=""
# LLM_MODEL_NAME="groq/llama-3.3-70b-versatile"
# LLM_MODEL_NAME="groq/llama3-70b-8192"
# LLM_MODEL_NAME="groq/meta-llama/llama-4-maverick-17b-128e-instruct"
# LLM_MODEL_NAME="groq/deepseek-r1-distill-llama-70b"
# LLM_MODEL_NAME="groq/qwen/qwen3-32b"

# # cerebras llama  context 16K, 30rpm, 800rph, 14400rpd
# LLM_BASE_URL=""
# LLM_API_KEY=""
# LLM_MODEL_NAME="cerebras/llama-3.3-70b"
# LLM_MODEL_NAME="cerebras/qwen-3-32b"
# LLM_MODEL_NAME="cerebras/qwen-3-235b-a22b"

# # google gemini
# LLM_BASE_URL=""
# LLM_API_KEY=""
# LLM_MODEL_NAME="gemini/gemini-2.5-flash"

# # ChatGPT API
# LLM_BASE_URL=""
# LLM_API_KEY=""
# LLM_MODEL_NAME="openai/gpt-3.5-turbo"
# LLM_MODEL_NAME="openai/gpt-4o-mini"
# LLM_MODEL_NAME="openai/gpt-4o"

# # cloudflare AI   NO TOOLS Support
# CLOUDFLARE_ACCOUNT_ID=""
# LLM_BASE_URL=""
# LLM_API_KEY=""
# LLM_MODEL_NAME="cloudflare/@cf/meta/llama-3.3-70b-instruct-fp8-fast"

# log llm input for debug purpose
LOG_LLM_INPUT=True
# log llm output for debug purpose
LOG_LLM_OUTPUT=True
